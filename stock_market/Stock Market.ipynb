{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "nyse.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNKhyuaul1C9",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "eee7d088-8a7f-493c-bea2-91834e16e9fb"
      },
      "source": [
        "# ! pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d dgawlik/nyse\n",
        "! unzip nyse.zip -d data_nyse\n",
        "! rm nyse.zip\n",
        "! ls\n",
        "! pip install  matplotlib\n",
        "! pip install  seaborn\n",
        "##https://www.kaggle.com/dgawlik/nyse##"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c7c1e37-4a5f-46d4-bee9-8213f8c47fd8\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2c7c1e37-4a5f-46d4-bee9-8213f8c47fd8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading nyse.zip to /content\n",
            " 82% 25.0M/30.7M [00:01<00:00, 14.2MB/s]\n",
            "100% 30.7M/30.7M [00:01<00:00, 21.8MB/s]\n",
            "Archive:  nyse.zip\n",
            "replace data_nyse/fundamentals.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42y23okHl1DD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install mpld3\n",
        "# ! ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T9-0Ztdl1DH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import mpld3#zoomable graphs\n",
        "mpld3.enable_notebook()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_columns', None)#Display all columns\n",
        "pd.set_option('display.max_rows', None)#Display all columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klyWrLALl1DL",
        "colab_type": "text"
      },
      "source": [
        "Context\n",
        "This dataset is a playground for fundamental and technical analysis. It is said that 30% of traffic on stocks is already generated by machines, can trading be fully automated? If not, there is still a lot to learn from historical data.\n",
        "\n",
        "Content\n",
        "Dataset consists of following files:\n",
        "\n",
        "*   **prices.csv**: raw, as-is daily prices. Most of data spans from 2010 to the end 2016, for companies new on stock market date range is shorter. There have been approx. 140 stock splits in that time, this set doesn't account for that.\n",
        "*    **prices-split-adjusted.csv**: same as prices, but there have been added adjustments for splits.\n",
        "*    **securities.csv**: general description of each company with division on sectors\n",
        "*    **fundamentals.csv**: metrics extracted from annual SEC 10K fillings (2012-2016), should be enough to derive most of popular fundamental indicators.\n",
        "Acknowledgements\n",
        "Prices were fetched from Yahoo Finance, fundamentals are from Nasdaq Financials, extended by some fields from EDGAR SEC databases.\n",
        "\n",
        "Inspiration\n",
        "Here is couple of things one could try out with this data:\n",
        "\n",
        "One day ahead prediction: Rolling Linear Regression, ARIMA, Neural Networks, LSTM\n",
        "Momentum/Mean-Reversion Strategies\n",
        "Security clustering, portfolio construction/hedging\n",
        "Which company has biggest chance of being bankrupt? Which one is undervalued (how prices behaved afterwards), what is Return on Investment?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAC9ptg4S6C-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "company_name = \"EA\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjwmVpJwl1DM",
        "colab_type": "text"
      },
      "source": [
        "#Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSI9aF2ml1DM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices_data_path = './data_nyse/prices.csv'\n",
        "securities_data_path = './data_nyse/securities.csv'\n",
        "prices_split_data_path = './data_nyse/prices-split-adjusted.csv'\n",
        "fundamentals_data_path = './data_nyse/fundamentals.csv'\n",
        "\n",
        "\n",
        "prices_data = pd.read_csv(prices_data_path)\n",
        "securities_data = pd.read_csv(securities_data_path)\n",
        "prices_split_data = pd.read_csv(prices_split_data_path)\n",
        "fundamentals_data = pd.read_csv(fundamentals_data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRyGmPZol1DQ",
        "colab_type": "text"
      },
      "source": [
        "#Inspect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAPRIoMtl1DR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfk-F7s-l1DW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "securities_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiY-zgXUl1Da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices_split_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg9daDZcl1Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fundamentals_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZkVQaarl1Dh",
        "colab_type": "text"
      },
      "source": [
        "Function to give us an idea of our Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWNk_P74l1Dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def observe_data(dataframeName):\n",
        "    dataframeName.info()\n",
        "    print(\"Dataframe Shape: \" + str(dataframeName.shape))\n",
        "    print(\"Dataframe Size: \" + str(dataframeName.size))\n",
        "    print(\"Number Of Rows: \" + str(len(dataframeName)))\n",
        "    print(\"Number Of Columns: \" + str(len(dataframeName.columns)))\n",
        "    #used to view some basic statistical details like percentile, mean, std etc. of a data frame or a series of numeric values\n",
        "    print(dataframeName.describe())#you can also pick specific columns as such: dataframe.columnName.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqV6kiptl1Dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "observe_data(prices_split_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3PH8VlFfgzc",
        "colab_type": "text"
      },
      "source": [
        "Number of Companies Per Sector/Industry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlFIHUoVevrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "ax = sns.countplot(y='GICS Sector', data=securities_data)\n",
        "plt.xticks(rotation=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAZ-P_c0fn4R",
        "colab_type": "text"
      },
      "source": [
        "Correlation among sectors - The higher the correlation, the more likely that the stocks are moving in the same direction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4_WfagogBlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "securities_data = securities_data.rename(columns = {'Ticker symbol' : 'symbol','GICS Sector' : 'sector'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA2nlPKngHtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices_data  = prices_data.merge(securities_data[['symbol','sector']], on = 'symbol')\n",
        "prices_data['date'] = pd.to_datetime(prices_data['date'])\n",
        "prices_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgTnw4gygkk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices_data = prices_data[prices_data['date'] >= '2016-01-01']#values after 2016 - we can change that later"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfpYhlPffk8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sector_pivot = pd.pivot_table(prices_data, values = 'close', index = ['date'],columns = ['sector']).reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51K99ISqgrnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(sector_pivot.corr() ,annot=True, cmap=\"coolwarm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnJOV5tSiTyD",
        "colab_type": "text"
      },
      "source": [
        "When building a diversified portfolio, investors seek negatively correlated stocks. Doing so reduces the risk of catastrophic losses in the portfolio and helps the investor sleep better at night. Assume the portfolio consists of two stocks and they are negatively correlated. This implies that when the price of one performs worse than usual, the other will likely do better than usual. However, risk takers would love to seek for positively correlated stocks for higher expected return, and of course, higher risk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az8BTXAfiU1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices_data['return'] = np.log(prices_data.close / prices_data.close.shift(1)) + 1\n",
        "prices_data['good'] = prices_data['symbol'] == prices_data['symbol'].shift(1)\n",
        "prices_data = prices_data.drop(prices_data[prices_data['good'] == False].index)\n",
        "prices_data.dropna(inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjzcdMBTiUyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "risk_free = 0.032\n",
        "sector_df = pd.DataFrame({'return' : (prices_data.groupby('sector')['return'].mean() - 1) * 252, 'stdev' : prices_data.groupby('sector')['return'].std()})\n",
        "sector_df['sharpe'] = (sector_df['return'] - risk_free) / sector_df['stdev']\n",
        "plt.figure(figsize = (12,8))\n",
        "ax = sns.barplot(x= sector_df['sharpe'], y = sector_df.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMwk6tsYisrV",
        "colab_type": "text"
      },
      "source": [
        "Sharpe ratio is often used to describe how good our portfolio is. The higher the sharpe ratio, the better the portfolio. A sharpe ratio more than 1 is acceptable to investors. As a matter of fact, we will only choose the sectors that have sharpe ratio more than 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj_I-emaiUtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "port_list = sector_df[sector_df['sharpe'] >= 1].index\n",
        "port_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wrKYxxfl1Do",
        "colab_type": "text"
      },
      "source": [
        "Function plotting historical closing values of a specific company from *prices_split_data* dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PEgV_VHl1Dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string = ', '.join(prices_split_data.symbol.unique())\n",
        "print(\"The 500 companies are: \" + string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auhT0UsQl1Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_closing_values(company_name):    \n",
        "    temp = prices_split_data.loc[prices_split_data[\"symbol\"] == company_name]\n",
        "    temp.close.plot()\n",
        "    plt.title(company_name)\n",
        "    plt.ylabel('Close')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziWJMMvGl1Dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! pip install plotly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jxLV5xEl1D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "def plot_candlestick_chart(company_name):    \n",
        "    df = prices_split_data.loc[prices_split_data[\"symbol\"] == company_name]\n",
        "    fig = go.Figure(data=[go.Candlestick(x=df.date,\n",
        "                    open=df.open,\n",
        "                    high=df.high,\n",
        "                    low=df.low,\n",
        "                    close=df.close)])\n",
        "\n",
        "    fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB6nYI_0l1D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_closing_values(company_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2zpTONNl1D6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_candlestick_chart(company_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPddIbn_l1EH",
        "colab_type": "text"
      },
      "source": [
        "A moving average (MA) is a widely used indicator in technical analysis that helps smooth out price action by filtering out the “noise” from random short-term price fluctuations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AX0EXoMl1EJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def moving_average(company_name):\n",
        "    df = prices_split_data.loc[prices_split_data[\"symbol\"] == company_name]\n",
        "    df = df[['close','date']]\n",
        "    df.reset_index(level=0, inplace=True)\n",
        "    plt.plot(df.date, df.close)\n",
        "    plt.show()\n",
        "    #SMA - Simple Moving Average\n",
        "    rolling_mean = df.close.rolling(20).mean()\n",
        "    rolling_mean2 = df.close.rolling(50).mean()\n",
        "    rolling_mean3 = df.close.rolling(100).mean()\n",
        "    plt.plot(df.date, df.close, label=str(company_name))\n",
        "    plt.plot(df.date, rolling_mean, label=str(company_name+' 20 Day SMA'), color='orange')\n",
        "    plt.plot(df.date, rolling_mean2, label=str(company_name+' 50 Day SMA'), color='magenta')\n",
        "    plt.plot(df.date, rolling_mean3, label=str(company_name+' 100 Day SMA'), color='red')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.show()\n",
        "    #EMA - Exponential Moving Average\n",
        "    exp1 = df.close.ewm(span=20, adjust=False).mean()\n",
        "    exp2 = df.close.ewm(span=50, adjust=False).mean()\n",
        "    exp3 = df.close.ewm(span=100, adjust=False).mean()\n",
        "    plt.plot(df.date, df.close, label=str(company_name))\n",
        "    plt.plot(df.date, exp1, label=str(company_name+' 20 Day EMA'), color='orange')\n",
        "    plt.plot(df.date, exp2, label=str(company_name+' 50 Day EMA'), color='magenta')\n",
        "    plt.plot(df.date, exp3, label=str(company_name+' 100 Day EMA'), color='red')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoXdHoX0l1EO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "moving_average(company_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4ibeaXpi2PV",
        "colab_type": "text"
      },
      "source": [
        "After having the list of sectors, we will choose from each sectors the most outstanding return stock. In real life you should choose many. However, in this example, I will pick only one for simple illustration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBu6Sig7i3Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats.mstats import gmean\n",
        "\n",
        "port_stock = []\n",
        "return_stock = []\n",
        "def get_stock(sector):\n",
        "    list_stocks = prices_data[prices_data['sector'] == sector]['symbol'].unique()\n",
        "    performance = prices_data.groupby('symbol')['return'].apply(lambda x : (gmean(x) - 1) * 252).sort_values(ascending = False)\n",
        "    \n",
        "    for i in range(len(performance)):\n",
        "        if performance.index[i] in list_stocks:\n",
        "            port_stock.append(performance.index[i])\n",
        "            return_stock.append(performance[i])\n",
        "            break\n",
        "    \n",
        "for sector in port_list:\n",
        "    get_stock(sector)\n",
        "\n",
        "return_stock"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPdRaSBVjGt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "port_df = prices_data[prices_data['symbol'].isin(port_stock)].pivot('date','symbol','return')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRwTqIm-jPhN",
        "colab_type": "text"
      },
      "source": [
        "Each portfolio will have different stock weights, or the allocation of your investment into each stock."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le6DheSwjToU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "return_pred = []\n",
        "weight_pred = []\n",
        "std_pred = []\n",
        "for i in range(1000):\n",
        "    random_matrix = np.array(np.random.dirichlet(np.ones(len(port_stock)),size=1)[0])\n",
        "    port_std = np.sqrt(np.dot(random_matrix.T, np.dot(port_df.cov(),random_matrix))) * np.sqrt(252)\n",
        "    port_return = np.dot(return_stock, random_matrix)\n",
        "    return_pred.append(port_return)\n",
        "    std_pred.append(port_std)\n",
        "    weight_pred.append(random_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30STSA15jVM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_output = pd.DataFrame({'weight' : weight_pred , 'return' : return_pred, 'stdev' :std_pred })\n",
        "pred_output['sharpe'] = (pred_output['return'] - risk_free) / pred_output['stdev']\n",
        "pred_output.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_ppnqpEjYVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_pos = pred_output.iloc[pred_output.sharpe.idxmax(),:]\n",
        "safe_pos = pred_output.iloc[pred_output.stdev.idxmin(),:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9Dm0R7kjadm",
        "colab_type": "text"
      },
      "source": [
        "After running 2000 simulations, we finally plot the results, as well as the options for the portfolio, either the best performing or the safest one for risk adverse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbdw7i_LjdF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplots(figsize=(15,10))\n",
        "#ax = sns.scatterplot(x=\"Stdev\", y=\"Return\", data=pred_output, hue = 'Sharpe', size = 'Sharpe', sizes=(20, 200))\n",
        "\n",
        "plt.scatter(pred_output.stdev,pred_output['return'],c=pred_output.sharpe,cmap='OrRd')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Volatility')\n",
        "plt.ylabel('Return')\n",
        "\n",
        "plt.scatter(max_pos.stdev,max_pos['return'],marker='^',color='r',s=500)\n",
        "plt.scatter(safe_pos.stdev,safe_pos['return'],marker='<',color='g',s=500)\n",
        "#ax.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0OTRe5hjiQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"The highest sharpe porfolio is {} sharpe, at {} volitality\".format(max_pos.sharpe.round(3),max_pos.stdev.round(3)))\n",
        "\n",
        "for i in range(len(port_stock)):\n",
        "    print(\"{} : {}%\".format(port_stock[i],(max_pos.weight[i] * 100).round(3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBtdVE4IjmCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"The safest porfolio is {} risk, {} sharpe\".format(safe_pos.stdev.round(3), safe_pos.sharpe.round(3)))\n",
        "for i in range(len(port_stock)):\n",
        "    print(\"{} : {}%\".format(port_stock[i],(safe_pos.weight[i] * 100).round(3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQKohN2kbUs-",
        "colab_type": "text"
      },
      "source": [
        "#Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aspytkabYq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "company_data = (prices_split_data.loc[prices_split_data['symbol']==company_name]\n",
        "         .drop(columns='symbol')\n",
        "         .sort_values(by='date',ascending=True)\n",
        "         .reset_index(drop=True)\n",
        "         .assign(**{'average': lambda df: df.loc[:,['open','high','low','close']].mean(axis=1), \n",
        "                    'EMA20': lambda df: df['average'].ewm(span=20, adjust=False).mean(), \n",
        "                    'EMA5': lambda df: df['average'].ewm(span=5, adjust=False).mean(), \n",
        "                    'dist_EMA20': lambda df: (df['average'] - df['EMA20'])/df['EMA20']*100, \n",
        "                    'dist_EMA5': lambda df: (df['average'] - df['EMA5'])/df['EMA5']*100}))\n",
        "company_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNdMVUMWcUsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use volume weighted averaged OHLC.mean to represent market average\n",
        "# comparison with SPY500 shows that market_average calculated this way is representative of overall market\n",
        "\n",
        "tickers_with_all_dates = prices_split_data.groupby('symbol').size().loc[lambda s: s.values==s.values.max()].index.to_list()\n",
        "market = (prices_split_data.loc[prices_split_data['symbol'].isin(tickers_with_all_dates)]\n",
        "          .assign(**{'average': lambda df: df.loc[:,['open','high','low','close']].mean(axis=1), \n",
        "                     'price x volume': lambda df: df['average']*df['volume']})\n",
        "          .groupby('date')\n",
        "          .agg(**{'price x volume sum': pd.NamedAgg(column='price x volume', aggfunc=np.sum), \n",
        "                  'volume sum': pd.NamedAgg(column='volume', aggfunc=np.sum)})\n",
        "          .assign(**{'market_average': lambda df: df['price x volume sum']/df['volume sum']})\n",
        "          .sort_index(ascending=True))\n",
        "\n",
        "company_data['market'] = market['market_average'].values\n",
        "company_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WavV2lrhc5MG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ax.plot(company_data.index[:120], company_data['dist_EMA20'][:120], label='dist_EMA20')\n",
        "ax.plot(company_data.index[:120], company_data['dist_EMA5'][:120], label='dist_EMA5')\n",
        "ax.set_xlabel('day')\n",
        "ax.set_ylabel('distance from moving mean')\n",
        "ax.legend(loc='best')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ax.plot(company_data.index[:120], company_data['open'][:120], label='open')\n",
        "ax.plot(company_data.index[:120], company_data['close'][:120], label='close')\n",
        "ax.set_xlabel('day')\n",
        "ax.set_ylabel(company_name)\n",
        "ax.legend(loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UhUXXDhj-Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def normalize_data(df):\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
        "    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
        "    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
        "    df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1,1))\n",
        "    df['close'] = min_max_scaler.fit_transform(df['close'].values.reshape(-1,1))\n",
        "    return df\n",
        "df = normalize_data(prices_split_data)\n",
        "df.plot(figsize=(23,10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "253qkloQTHmF",
        "colab_type": "text"
      },
      "source": [
        "#Risk Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25AbXzFdl1EW",
        "colab_type": "text"
      },
      "source": [
        "We've done some baseline analysis, let's go ahead and dive a little deeper. We're now going to analyze the risk of the stock. In order to do so we'll need to take a closer look at the daily changes of the stock, and not just its absolute value, using the *pct_change* function, which will return the percentage change between the current and a prior element."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4sBIfqLl1EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def risk_computation(company_name):\n",
        "    risks = prices_split_data.loc[prices_split_data[\"symbol\"] == company_name].close.pct_change()\n",
        "    print(risks.head())\n",
        "    risks.plot( legend=True, linestyle='--', marker='o')\n",
        "    #Histogram & KDE Plot\n",
        "    # Note the use of dropna() here, otherwise the NaN values can't be read by seaborn\n",
        "    plt.figure(figsize=(12, 12))\n",
        "\n",
        "    sns.distplot(risks.dropna(), bins=100, color='purple')\n",
        "    plt.ylabel('Daily Return')\n",
        "    plt.title(company_name)\n",
        "    # Could have also done:\n",
        "    #AAPL['Daily Return'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NGvxeNwl1Ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "risk_computation(company_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YA1tK_7l1Ek",
        "colab_type": "text"
      },
      "source": [
        "#Train our Model & Display our predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXnDmXR7RDr2",
        "colab": {}
      },
      "source": [
        "# %tensorflow_version 2.x\n",
        "# import tensorflow as tf\n",
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   raise SystemError('GPU device not found')\n",
        "# print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I14uD65lNT6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorflow_version 2.x\n",
        "# import tensorflow as tf\n",
        "# import timeit\n",
        "\n",
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   print(\n",
        "#       '\\n\\nThis error most likely means that this notebook is not '\n",
        "#       'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "#       'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "#   raise SystemError('GPU device not found')\n",
        "\n",
        "# def cpu():\n",
        "#   with tf.device('/cpu:0'):\n",
        "#     random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "#     net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "#     return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "# def gpu():\n",
        "#   with tf.device('/device:GPU:0'):\n",
        "#     random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "#     net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "#     return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# # We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "# cpu()\n",
        "# gpu()\n",
        "\n",
        "# # Run the op several times.\n",
        "# print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "#       '(batch x height x width x channel). Sum of ten runs.')\n",
        "# print('CPU (s):')\n",
        "# cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "# print(cpu_time)\n",
        "# print('GPU (s):')\n",
        "# gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "# print(gpu_time)\n",
        "# print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTyGXFhMl1El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices_split_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND6sfZtBl1Er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! pip install sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC1Zvqgdl1E6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oof = prices_split_data\n",
        "\n",
        "df = oof.loc[prices_split_data[\"symbol\"] == company_name]\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('Close Price History')\n",
        "plt.plot(df['date'],df['close'])\n",
        "plt.xlabel('date', fontsize=18)\n",
        "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
        "plt.show()\n",
        "\n",
        "#Create a new dataframe with only the 'Close column\n",
        "data = df.filter(['close'])\n",
        "#Convert the dataframe to a numpy array\n",
        "dataset = data.values\n",
        "#Get the number of rows to train the model on\n",
        "training_data_len = int(np.ceil( len(dataset) * .8 ))\n",
        "\n",
        "#Scale the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(dataset)\n",
        "\n",
        "#Create the training data set\n",
        "#Create the scaled training data set\n",
        "train_data = scaled_data[0:int(training_data_len), :]\n",
        "#Split the data into x_train and y_train data sets\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(60, len(train_data)):\n",
        "    x_train.append(train_data[i-60:i, 0])\n",
        "    y_train.append(train_data[i, 0])\n",
        "    if i<= 61:\n",
        "        print(x_train)\n",
        "        print(y_train)\n",
        "        print()\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays \n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "#Reshape the data\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "x_train.shape\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "\n",
        "#Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
        "model.add(LSTM(50, return_sequences= False))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "#Train the model\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
        "\n",
        "#Create the testing data set\n",
        "#Create a new array containing scaled values from index 1543 to 2002 \n",
        "test_data = scaled_data[training_data_len - 60: , :]\n",
        "#Create the data sets x_test and y_test\n",
        "x_test = []\n",
        "y_test = dataset[training_data_len:, :]\n",
        "for i in range(60, len(test_data)):\n",
        "    x_test.append(test_data[i-60:i, 0])\n",
        "\n",
        "# Convert the data to a numpy array\n",
        "x_test = np.array(x_test)\n",
        "# Reshape the data\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
        "\n",
        "# Get the models predicted price values \n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43W8Agskl1FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Get the root mean squared error (RMSE)\n",
        "rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
        "rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyevTgvi46vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot the data\n",
        "train = data[:training_data_len]\n",
        "valid = data[training_data_len:]\n",
        "valid['Predictions']= predictions\n",
        "valid.head()\n",
        "# valid['Predictions'] = predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI0Em9M8H3ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Visualize the data\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title(company_name)\n",
        "plt.xlabel('Date', fontsize=18)\n",
        "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
        "plt.plot(train['close'])\n",
        "plt.plot(valid[['close', 'Predictions']])\n",
        "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}